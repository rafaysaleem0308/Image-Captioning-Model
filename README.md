# Image-Captioning-Model
ðŸš€ Built an End-to-End Image Captioning System Using Deep Learning
I recently developed a complete Image Caption Generator that converts images into natural language descriptions using a Seq2Seq deep learning architecture.
This project integrates computer vision and NLP into a full pipeline â€” from feature extraction to deployment.
ðŸ”Ž Project Highlights
ðŸ”¹ Feature Extraction
Pretrained ResNet50 (ImageNet weights)
Removed final classification layer
Generated 2048-dimensional image embeddings
GPU-accelerated batch processing with PyTorch
ðŸ”¹ Text Processing & Vocabulary Engineering
Caption cleaning and tokenization
Custom vocabulary with frequency thresholding
Special tokens: <start>, <end>, <pad>, <unk>
Proper train/validation/test split by image to avoid data leakage
ðŸ”¹ Model Architecture
Encoder: Linear â†’ BatchNorm â†’ ReLU â†’ Dropout
Decoder: Embedding â†’ Multi-layer LSTM â†’ Linear output layer
Teacher Forcing during training
Gradient clipping for stability
ðŸ”¹ Training Setup
CrossEntropyLoss (ignoring padding tokens)
Adam optimizer
Validation monitoring + best model checkpointing
GPU training
ðŸ”¹ Inference Methods
Greedy Search
Beam Search (for improved caption quality)
ðŸ”¹ Evaluation
BLEU-4 score
Token-level Precision, Recall, F1-score
Visual comparison between generated and ground-truth captions
ðŸ”¹ Deployment
Built an interactive Gradio web app
Users can upload an image and receive AI-generated captions in real time
ðŸ›  Tech Stack
Python | PyTorch | torchvision | NumPy | Pandas | NLTK | Scikit-learn | Matplotlib | Gradio | Kaggle GPU
